# OTel Collector メモリ高騰シナリオと診断ガイド (厳選4種)

実務で遭遇しやすく、かつ Collector の安定稼働を脅かす典型的なメモリ高騰シナリオに絞り、その際の特徴（シグネチャ）を理解するためのガイド。

---

## クイックリファレンス

| 新番号 | シナリオ | コマンド | 主な観察ポイント |
|-------|---------|---------|-----------------|
| **1** | **下流停止** | `make scenario-1` | Queue Usage 100%, Receiver Refused |
| **2** | **キャパシティ不足** | `make scenario-2` | Queue 上下動, CPU 張り付き, 慢性的な Refused |
| **3** | **メモリリーク** | `make scenario-3` | RSS 右肩上がり, Heap Alloc は安定 |
| **4** | **高カーディナリティ** | `make scenario-4` | Heap の段階的な増加, 戻らないメモリ |

---

## シナリオ1: 下流（バックエンド）の遅延・停止

**現象**:
Jaeger や Prometheus などのバックエンドが応答しない、または極端に遅い場合。Collector はデータをメモリ上のキューに溜め込み、メモリ使用量が急増する。

**再現手順**:
1. `make scenario-1` で負荷開始。
2. `docker compose stop jaeger` でバックエンドを停止。

**診断のシグネチャ (Grafana)**:
- **Queue Usage**: 0% から一直線に **100%** に張り付く。
- **Heap Memory**: Queue の蓄積に伴い急増。リミット到達時に **Force GC による急落と高止まり** が発生。
- **Receiver Refused**: Queue が満杯になると `otelcol_receiver_refused_spans_total` が増加し、データ欠損が始まる。

**対処法**:
- `sending_queue` のサイズを適正化（大きくしすぎない）。
- `memory_limiter` を設定し、プロセス全体のクラッシュ（OOM Kill）を防ぐ。

---

## シナリオ2: 慢性的な入力過多（キャパシティ不足）

**現象**:
Collector の処理能力（CPU/Network）の限界を超えるデータが常に流入している状態。バックエンドは生きているが、処理が追いつかずメモリが上限付近で推移する。

**再現手順**:
1. `make scenario-2` を実行。

**診断のシグネチャ (Grafana)**:
- **Queue Usage**: 100% に張り付くのではなく、**高位（70-90%以上）で激しく上下動** する。
- **CPU Usage**: 常に高い使用率。
- **Receiver Refused**: 停止していないにもかかわらず、恒常的に `refused` が発生する。

**対処法**:
- Collector の水平スケール（台数を増やす）。
- 不要な属性の削除やサンプリングの導入。

---

## シナリオ3: メモリリーク（または Processor のバグ）

**現象**:
負荷が一定であるにも関わらず、RSS（物理メモリ）が時間とともに増え続け、最終的に OOM Kill される。Go ランタイム管理外の領域（CGO やバグ）でのリークが疑われるケース。

**再現手順**:
1. `make scenario-3` を実行し、10分以上観察。

**診断のシグネチャ (Grafana)**:
- **RSS (Physical Memory)**: 時間経過とともに線形に増加（右肩上がり）。
- **Heap Alloc**: 一定、または正常な上下動を繰り返す。
- **乖離の発生**: RSS と Heap Alloc の差分が開き続けるのが決定的証拠。

**対処法**:
- 特定のステートフルな Processor（groupbyattrs 等）の除外テスト。
- Collector バイナリのバージョン変更。

---

## シナリオ4: 属性爆発（High Cardinality）

**現象**:
`groupbyattrs` や `groupbytrace` プロセッサを使用している際、属性のユニーク値（IDやハッシュ）が多すぎて、メモリ上のマップが肥大化し、メモリを解放できなくなる。

**再現手順**:
1. `make scenario-4` を実行。

**診断のシグネチャ (Grafana)**:
- **Heap Memory**: 段階的に増加し、負荷が下がっても **メモリが元の水準まで戻らない**。
- **GC CPU Fraction**: マップの走査により GC のオーバーヘッド（CPU負荷）が増加する。

**対処法**:
- グループ化キーから高カーディナリティ属性を除外。
- `memory_limiter` をステートフルプロセッサの **前** に配置する。

---

## 診断フローチャート（簡易版）

```
メモリ高騰を検知
       │
       ▼
┌──────────────────┐
│ Queue Usage は？ │─── 100% ──▶ シナリオ1 (下流停止)
└──────────────────┘
       │
      正常〜高位
       │
       ▼
┌──────────────────┐
│ RSS vs Heap は？ │─── 乖離大 ─▶ シナリオ3 (リーク)
└──────────────────┘
       │
      同期
       │
       ▼
┌──────────────────┐
│ Refused は？     │─── 恒常的 ─▶ シナリオ2 (キャパ過多)
└──────────────────┘
       │
      なし
       │
       ▼
シナリオ4 (高カーディナリティ)
```
