// loadgen - OpenTelemetry Collector ã®è² è·ãƒ†ã‚¹ãƒˆç”¨ãƒ„ãƒ¼ãƒ«
// memory_limiter ã‚’ç™ºç«ã•ã›ã‚‹ãŸã‚ã®é«˜è² è·ã‚·ãƒŠãƒªã‚ªã‚’æä¾›
package main

import (
	"context"
	"flag"
	"fmt"
	"log"
	"math/rand"
	"os"
	"os/signal"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"github.com/google/uuid"
	"go.opentelemetry.io/otel"
	"go.opentelemetry.io/otel/attribute"
	"go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc"
	"go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc"
	"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
	otellog "go.opentelemetry.io/otel/log"
	"go.opentelemetry.io/otel/log/global"
	"go.opentelemetry.io/otel/metric"
	sdklog "go.opentelemetry.io/otel/sdk/log"
	sdkmetric "go.opentelemetry.io/otel/sdk/metric"
	"go.opentelemetry.io/otel/sdk/resource"
	sdktrace "go.opentelemetry.io/otel/sdk/trace"
	semconv "go.opentelemetry.io/otel/semconv/v1.26.0"
	"go.opentelemetry.io/otel/trace"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

// Config ã¯è² è·ãƒ†ã‚¹ãƒˆã®è¨­å®š
type Config struct {
	Endpoint        string
	Scenario        string
	Duration        time.Duration
	WorkerCount     int
	SpansPerSecond  int
	SpanDepth       int
	AttributeSize   int  // å±æ€§å€¤ã®æ–‡å­—åˆ—é•·ï¼ˆãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã«å½±éŸ¿ï¼‰
	AttributeCount  int  // å±æ€§ã®æ•°
	MetricsEnabled  bool // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚‚é€ã‚‹ã‹
	LogsEnabled     bool // ãƒ­ã‚°ã‚‚é€ã‚‹ã‹
	HighCardinality bool // é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£å±æ€§ã‚’ä½¿ã†ã‹ï¼ˆã‚·ãƒŠãƒªã‚ª6ç”¨ï¼‰
}

var (
	totalSpans atomic.Int64
	totalLogs  atomic.Int64
)

func main() {
	cfg := parseFlags()

	log.Printf("========================================")
	log.Printf("Loadgen starting...")
	log.Printf("  Endpoint:         %s", cfg.Endpoint)
	log.Printf("  Scenario:         %s", cfg.Scenario)
	log.Printf("  Duration:         %s", cfg.Duration)
	log.Printf("  Workers:          %d", cfg.WorkerCount)
	log.Printf("  Spans/sec:        %d", cfg.SpansPerSecond)
	log.Printf("  Span Depth:       %d", cfg.SpanDepth)
	log.Printf("  Attribute Size:   %d bytes", cfg.AttributeSize)
	log.Printf("  Attribute Count:  %d", cfg.AttributeCount)
	log.Printf("  Metrics:          %v", cfg.MetricsEnabled)
	log.Printf("  Logs:             %v", cfg.LogsEnabled)
	log.Printf("  High Cardinality: %v", cfg.HighCardinality)
	log.Printf("========================================")

	ctx, cancel := signal.NotifyContext(context.Background(), os.Interrupt)
	defer cancel()

	// gRPC æ¥ç¶š
	conn, err := grpc.NewClient(cfg.Endpoint,
		grpc.WithTransportCredentials(insecure.NewCredentials()),
	)
	if err != nil {
		log.Fatalf("Failed to create gRPC connection: %v", err)
	}
	defer conn.Close()

	// Resource ä½œæˆ
	res, err := resource.New(ctx,
		resource.WithAttributes(
			semconv.ServiceName("loadgen"),
			semconv.ServiceVersion("1.0.0"),
		),
	)
	if err != nil {
		log.Fatalf("Failed to create resource: %v", err)
	}

	// Tracer Provider åˆæœŸåŒ–
	tracerProvider, err := initTracerProvider(ctx, res, conn)
	if err != nil {
		log.Fatalf("Failed to init tracer provider: %v", err)
	}
	defer func() {
		shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 10*time.Second)
		defer shutdownCancel()
		if err := tracerProvider.Shutdown(shutdownCtx); err != nil {
			log.Printf("Error shutting down tracer provider: %v", err)
		}
	}()

	// Meter Provider åˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
	var meterProvider *sdkmetric.MeterProvider
	if cfg.MetricsEnabled {
		meterProvider, err = initMeterProvider(ctx, res, conn)
		if err != nil {
			log.Fatalf("Failed to init meter provider: %v", err)
		}
		defer func() {
			shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 10*time.Second)
			defer shutdownCancel()
			if err := meterProvider.Shutdown(shutdownCtx); err != nil {
				log.Printf("Error shutting down meter provider: %v", err)
			}
		}()
	}

	// Logger Provider åˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
	var loggerProvider *sdklog.LoggerProvider
	if cfg.LogsEnabled {
		loggerProvider, err = initLoggerProvider(ctx, res, conn)
		if err != nil {
			log.Fatalf("Failed to init logger provider: %v", err)
		}
		defer func() {
			shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 10*time.Second)
			defer shutdownCancel()
			if err := loggerProvider.Shutdown(shutdownCtx); err != nil {
				log.Printf("Error shutting down logger provider: %v", err)
			}
		}()
	}

	tracer := otel.Tracer("loadgen")
	var meter metric.Meter
	if cfg.MetricsEnabled {
		meter = otel.Meter("loadgen")
	}
	var logger otellog.Logger
	if cfg.LogsEnabled {
		logger = global.GetLoggerProvider().Logger("loadgen")
	}

	// ã‚·ãƒŠãƒªã‚ªå®Ÿè¡Œ
	runScenario(ctx, cfg, tracer, meter, logger)

	log.Printf("========================================")
	log.Printf("Loadgen finished")
	log.Printf("  Total spans sent: %d", totalSpans.Load())
	if cfg.LogsEnabled {
		log.Printf("  Total logs sent:  %d", totalLogs.Load())
	}
	log.Printf("========================================")
}

func parseFlags() Config {
	cfg := Config{}

	flag.StringVar(&cfg.Endpoint, "endpoint", "localhost:4317", "OTel Collector endpoint")
	flag.StringVar(&cfg.Scenario, "scenario", "sustained", "Load scenario: burst, sustained, spike, rampup")
	flag.DurationVar(&cfg.Duration, "duration", 60*time.Second, "Test duration")
	flag.IntVar(&cfg.WorkerCount, "workers", 10, "Number of concurrent workers")
	flag.IntVar(&cfg.SpansPerSecond, "rate", 1000, "Target spans per second (total across all workers)")
	flag.IntVar(&cfg.SpanDepth, "depth", 5, "Span nesting depth per trace")
	flag.IntVar(&cfg.AttributeSize, "attr-size", 256, "Size of each attribute value in bytes")
	flag.IntVar(&cfg.AttributeCount, "attr-count", 10, "Number of attributes per span")
	flag.BoolVar(&cfg.MetricsEnabled, "metrics", true, "Enable metrics generation")
	flag.BoolVar(&cfg.LogsEnabled, "logs", false, "Enable logs generation")
	flag.BoolVar(&cfg.HighCardinality, "high-cardinality", false, "Use high cardinality attributes (UUID per span)")

	flag.Parse()
	return cfg
}

func initTracerProvider(ctx context.Context, res *resource.Resource, conn *grpc.ClientConn) (*sdktrace.TracerProvider, error) {
	exporter, err := otlptracegrpc.New(ctx, otlptracegrpc.WithGRPCConn(conn))
	if err != nil {
		return nil, fmt.Errorf("failed to create trace exporter: %w", err)
	}

	// BatchSpanProcessor - gRPC ã® 4MiB åˆ¶é™ã‚’è¶…ãˆãªã„ã‚ˆã†ã«ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’èª¿æ•´
	// å¤§ããªå±æ€§ã‚’æŒã¤ã‚¹ãƒ‘ãƒ³ã§ã‚‚ 4MiB ã«åã¾ã‚‹ã‚ˆã†ã€å°ã•ã„ãƒãƒƒãƒã§é »ç¹ã«é€ä¿¡
	bsp := sdktrace.NewBatchSpanProcessor(exporter,
		sdktrace.WithMaxQueueSize(4096),                // ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚º
		sdktrace.WithMaxExportBatchSize(32),            // å°ã•ã„ãƒãƒƒãƒï¼ˆ4MiBåˆ¶é™å†…ã«ç¢ºå®Ÿã«åã‚ã‚‹ï¼‰
		sdktrace.WithBatchTimeout(50*time.Millisecond), // çŸ­ã„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã§é »ç¹ã«é€ä¿¡
	)

	tp := sdktrace.NewTracerProvider(
		sdktrace.WithSampler(sdktrace.AlwaysSample()),
		sdktrace.WithResource(res),
		sdktrace.WithSpanProcessor(bsp),
	)
	otel.SetTracerProvider(tp)

	return tp, nil
}

func initMeterProvider(ctx context.Context, res *resource.Resource, conn *grpc.ClientConn) (*sdkmetric.MeterProvider, error) {
	exporter, err := otlpmetricgrpc.New(ctx, otlpmetricgrpc.WithGRPCConn(conn))
	if err != nil {
		return nil, fmt.Errorf("failed to create metric exporter: %w", err)
	}

	mp := sdkmetric.NewMeterProvider(
		sdkmetric.WithResource(res),
		sdkmetric.WithReader(sdkmetric.NewPeriodicReader(exporter, sdkmetric.WithInterval(1*time.Second))),
	)
	otel.SetMeterProvider(mp)

	return mp, nil
}

func initLoggerProvider(ctx context.Context, res *resource.Resource, conn *grpc.ClientConn) (*sdklog.LoggerProvider, error) {
	exporter, err := otlploggrpc.New(ctx, otlploggrpc.WithGRPCConn(conn))
	if err != nil {
		return nil, fmt.Errorf("failed to create log exporter: %w", err)
	}

	// BatchProcessor for logs
	batchProcessor := sdklog.NewBatchProcessor(exporter,
		sdklog.WithMaxQueueSize(4096),
		sdklog.WithExportMaxBatchSize(32),
		sdklog.WithExportInterval(50*time.Millisecond),
	)

	lp := sdklog.NewLoggerProvider(
		sdklog.WithResource(res),
		sdklog.WithProcessor(batchProcessor),
	)
	global.SetLoggerProvider(lp)

	return lp, nil
}

func runScenario(ctx context.Context, cfg Config, tracer trace.Tracer, meter metric.Meter, logger otellog.Logger) {
	switch cfg.Scenario {
	case "burst":
		runBurstScenario(ctx, cfg, tracer, meter, logger)
	case "sustained":
		runSustainedScenario(ctx, cfg, tracer, meter, logger)
	case "spike":
		runSpikeScenario(ctx, cfg, tracer, meter, logger)
	case "rampup":
		runRampupScenario(ctx, cfg, tracer, meter, logger)
	default:
		log.Fatalf("Unknown scenario: %s", cfg.Scenario)
	}
}

// burst: å¯èƒ½ãªé™ã‚Šé€Ÿãã‚¹ãƒ‘ãƒ³ã‚’é€ã‚Šç¶šã‘ã‚‹ï¼ˆrateåˆ¶é™ãªã—ï¼‰
func runBurstScenario(ctx context.Context, cfg Config, tracer trace.Tracer, meter metric.Meter, logger otellog.Logger) {
	log.Println("[BURST] Starting burst mode - sending as fast as possible")

	deadline := time.Now().Add(cfg.Duration)
	var wg sync.WaitGroup

	for i := 0; i < cfg.WorkerCount; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			for time.Now().Before(deadline) {
				select {
				case <-ctx.Done():
					return
				default:
					generateTrace(ctx, tracer, meter, logger, cfg, workerID)
				}
			}
		}(i)
	}

	// é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ
	go reportProgress(ctx, deadline, cfg.LogsEnabled)

	wg.Wait()
}

// sustained: æŒ‡å®šãƒ¬ãƒ¼ãƒˆã§ç¶™ç¶šçš„ã«é€ã‚Šç¶šã‘ã‚‹
func runSustainedScenario(ctx context.Context, cfg Config, tracer trace.Tracer, meter metric.Meter, logger otellog.Logger) {
	log.Printf("[SUSTAINED] Target rate: %d spans/sec for %s", cfg.SpansPerSecond, cfg.Duration)

	deadline := time.Now().Add(cfg.Duration)
	var wg sync.WaitGroup

	// å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã®é€ä¿¡ãƒ¬ãƒ¼ãƒˆ
	ratePerWorker := cfg.SpansPerSecond / cfg.WorkerCount
	if ratePerWorker < 1 {
		ratePerWorker = 1
	}
	interval := time.Second / time.Duration(ratePerWorker)

	for i := 0; i < cfg.WorkerCount; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			ticker := time.NewTicker(interval)
			defer ticker.Stop()

			for time.Now().Before(deadline) {
				select {
				case <-ctx.Done():
					return
				case <-ticker.C:
					generateTrace(ctx, tracer, meter, logger, cfg, workerID)
				}
			}
		}(i)
	}

	go reportProgress(ctx, deadline, cfg.LogsEnabled)

	wg.Wait()
}

// spike: é€šå¸¸è² è· â†’ ã‚¹ãƒ‘ã‚¤ã‚¯ â†’ é€šå¸¸è² è· ã‚’ç¹°ã‚Šè¿”ã™
func runSpikeScenario(ctx context.Context, cfg Config, tracer trace.Tracer, meter metric.Meter, logger otellog.Logger) {
	log.Println("[SPIKE] Alternating between normal and spike load")

	deadline := time.Now().Add(cfg.Duration)
	var wg sync.WaitGroup

	normalRate := cfg.SpansPerSecond / 10 // é€šå¸¸ã¯1/10
	spikeRate := cfg.SpansPerSecond       // ã‚¹ãƒ‘ã‚¤ã‚¯æ™‚ã¯ãƒ•ãƒ«ãƒ¬ãƒ¼ãƒˆ

	currentRate := &atomic.Int64{}
	currentRate.Store(int64(normalRate))

	// ãƒ¬ãƒ¼ãƒˆåˆ‡ã‚Šæ›¿ãˆã‚´ãƒ«ãƒ¼ãƒãƒ³
	go func() {
		ticker := time.NewTicker(10 * time.Second)
		defer ticker.Stop()
		isSpike := false

		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				if time.Now().After(deadline) {
					return
				}
				isSpike = !isSpike
				if isSpike {
					log.Printf("[SPIKE] ğŸ”¥ SPIKE START - rate: %d/sec", spikeRate)
					currentRate.Store(int64(spikeRate))
				} else {
					log.Printf("[SPIKE] ğŸ˜Œ Normal mode - rate: %d/sec", normalRate)
					currentRate.Store(int64(normalRate))
				}
			}
		}
	}()

	for i := 0; i < cfg.WorkerCount; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			for time.Now().Before(deadline) {
				select {
				case <-ctx.Done():
					return
				default:
					rate := currentRate.Load()
					ratePerWorker := rate / int64(cfg.WorkerCount)
					if ratePerWorker < 1 {
						ratePerWorker = 1
					}
					interval := time.Second / time.Duration(ratePerWorker)
					time.Sleep(interval)
					generateTrace(ctx, tracer, meter, logger, cfg, workerID)
				}
			}
		}(i)
	}

	go reportProgress(ctx, deadline, cfg.LogsEnabled)

	wg.Wait()
}

// rampup: å¾ã€…ã«è² è·ã‚’ä¸Šã’ã¦ã„ã
func runRampupScenario(ctx context.Context, cfg Config, tracer trace.Tracer, meter metric.Meter, logger otellog.Logger) {
	log.Println("[RAMPUP] Gradually increasing load")

	deadline := time.Now().Add(cfg.Duration)
	var wg sync.WaitGroup

	currentRate := &atomic.Int64{}
	currentRate.Store(int64(cfg.SpansPerSecond / 10))

	// 10ç§’ã”ã¨ã«ãƒ¬ãƒ¼ãƒˆã‚’ä¸Šã’ã‚‹
	go func() {
		ticker := time.NewTicker(10 * time.Second)
		defer ticker.Stop()
		step := int64(cfg.SpansPerSecond / 10)
		maxRate := int64(cfg.SpansPerSecond)

		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				if time.Now().After(deadline) {
					return
				}
				newRate := currentRate.Load() + step
				if newRate > maxRate {
					newRate = maxRate
				}
				currentRate.Store(newRate)
				log.Printf("[RAMPUP] ğŸ“ˆ Rate increased to %d/sec", newRate)
			}
		}
	}()

	for i := 0; i < cfg.WorkerCount; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			for time.Now().Before(deadline) {
				select {
				case <-ctx.Done():
					return
				default:
					rate := currentRate.Load()
					ratePerWorker := rate / int64(cfg.WorkerCount)
					if ratePerWorker < 1 {
						ratePerWorker = 1
					}
					interval := time.Second / time.Duration(ratePerWorker)
					time.Sleep(interval)
					generateTrace(ctx, tracer, meter, logger, cfg, workerID)
				}
			}
		}(i)
	}

	go reportProgress(ctx, deadline, cfg.LogsEnabled)

	wg.Wait()
}

// generateTrace ã¯ãƒã‚¹ãƒˆã•ã‚ŒãŸã‚¹ãƒ‘ãƒ³ã‚’ç”Ÿæˆ
func generateTrace(ctx context.Context, tracer trace.Tracer, meter metric.Meter, logger otellog.Logger, cfg Config, workerID int) {
	// å¤§ããªå±æ€§ã‚’ç”Ÿæˆï¼ˆãƒ¡ãƒ¢ãƒªæ¶ˆè²»ç”¨ï¼‰
	attrs := generateAttributes(cfg.AttributeCount, cfg.AttributeSize, workerID, cfg.HighCardinality)

	// ãƒ«ãƒ¼ãƒˆã‚¹ãƒ‘ãƒ³
	ctx, rootSpan := tracer.Start(ctx, fmt.Sprintf("worker-%d-root", workerID),
		trace.WithAttributes(attrs...),
	)

	// ãƒã‚¹ãƒˆã•ã‚ŒãŸå­ã‚¹ãƒ‘ãƒ³ã‚’ç”Ÿæˆ
	generateNestedSpans(ctx, tracer, cfg, workerID, cfg.SpanDepth, attrs)

	rootSpan.End()
	totalSpans.Add(int64(cfg.SpanDepth + 1))

	// ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚‚é€ã‚‹
	if meter != nil {
		counter, _ := meter.Int64Counter("loadgen.traces.generated")
		counter.Add(ctx, 1, metric.WithAttributes(
			attribute.Int("worker_id", workerID),
		))
	}

	// ãƒ­ã‚°ã‚‚é€ã‚‹
	if logger != nil {
		generateLog(ctx, logger, cfg, workerID, attrs)
	}
}

func generateNestedSpans(ctx context.Context, tracer trace.Tracer, cfg Config, workerID int, depth int, attrs []attribute.KeyValue) {
	if depth <= 0 {
		return
	}

	ctx, span := tracer.Start(ctx, fmt.Sprintf("worker-%d-child-%d", workerID, depth),
		trace.WithAttributes(attrs...),
	)
	defer span.End()

	// ãƒ©ãƒ³ãƒ€ãƒ ãªå‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆå°‘ã—é…å»¶ã‚’å…¥ã‚Œã‚‹ï¼‰
	time.Sleep(time.Duration(rand.Intn(5)) * time.Millisecond)

	generateNestedSpans(ctx, tracer, cfg, workerID, depth-1, attrs)
}

// generateAttributes ã¯å¤§ããªå±æ€§ã‚’ç”Ÿæˆã™ã‚‹
func generateAttributes(count, size int, workerID int, highCardinality bool) []attribute.KeyValue {
	attrs := make([]attribute.KeyValue, count)

	// å¤§ããªæ–‡å­—åˆ—ã‚’ç”Ÿæˆ
	bigValue := strings.Repeat("x", size)

	for i := 0; i < count; i++ {
		var value string
		if highCardinality {
			// é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£: æ¯å›ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªUUIDã‚’å«ã‚ã‚‹
			value = fmt.Sprintf("%s_worker%d_attr%d_%s", bigValue, workerID, i, uuid.New().String())
		} else {
			value = fmt.Sprintf("%s_worker%d_attr%d_%d", bigValue, workerID, i, rand.Int())
		}
		attrs[i] = attribute.String(
			fmt.Sprintf("attr_%d", i),
			value,
		)
	}

	return attrs
}

// generateLog ã¯ OTel ãƒ­ã‚°ã‚’ç”Ÿæˆã™ã‚‹
func generateLog(ctx context.Context, logger otellog.Logger, cfg Config, workerID int, attrs []attribute.KeyValue) {
	// å¤§ããªãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
	logBody := strings.Repeat("Log message content. ", cfg.AttributeSize/20+1)

	// otellog.KeyValue ã«å¤‰æ›
	logAttrs := make([]otellog.KeyValue, len(attrs))
	for i, attr := range attrs {
		logAttrs[i] = otellog.String(string(attr.Key), attr.Value.AsString())
	}

	// ãƒ­ã‚°ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ
	record := otellog.Record{}
	record.SetTimestamp(time.Now())
	record.SetBody(otellog.StringValue(fmt.Sprintf("[Worker-%d] %s", workerID, logBody)))
	record.SetSeverity(otellog.SeverityInfo)
	record.AddAttributes(logAttrs...)

	logger.Emit(ctx, record)
	totalLogs.Add(1)
}

func reportProgress(ctx context.Context, deadline time.Time, logsEnabled bool) {
	ticker := time.NewTicker(5 * time.Second)
	defer ticker.Stop()

	lastSpanCount := int64(0)
	lastLogCount := int64(0)

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			if time.Now().After(deadline) {
				return
			}
			currentSpans := totalSpans.Load()
			spanRate := (currentSpans - lastSpanCount) / 5
			remaining := time.Until(deadline).Round(time.Second)

			if logsEnabled {
				currentLogs := totalLogs.Load()
				logRate := (currentLogs - lastLogCount) / 5
				log.Printf("[PROGRESS] Spans: %d (%d/sec), Logs: %d (%d/sec), Remaining: %s",
					currentSpans, spanRate, currentLogs, logRate, remaining)
				lastLogCount = currentLogs
			} else {
				log.Printf("[PROGRESS] Spans: %d (rate: %d/sec), Remaining: %s", currentSpans, spanRate, remaining)
			}
			lastSpanCount = currentSpans
		}
	}
}
